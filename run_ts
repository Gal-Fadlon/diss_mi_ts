#!/bin/bash

################################################################################################
### sbatch configuration parameters must start with #SBATCH and must precede any other commands.
### To ignore, just add another # - like so: ##SBATCH
################################################################################################

#SBATCH --time 7-00:00:00    ### limit the time of job running. Make sure it is not greater than the partition time limit!! Format: D-H:MM:SS
#SBATCH --job-name time_series_ours_3   ### name of the job
#SBATCH --output time_series_ours_3-%J.out    ### output log for running job - %J for job number
#SBATCH --error time_series_ours_3-%J.out.err      ### stderr log for running job
#SBATCH --gpus=rtx_3090:1    ### number of GPUs, allocating more than 1 requires IT team's permission
#SBATCH --partition main        ### golden ticket to use the 3090s
#SBATCH --qos normal
#SBATCH --mem=32G    ### amount of RAM memory, allocating more than 60G requires IT team's permission
#SBATCH --cpus-per-task=6   ### number of CPU cores, allocating more than 10G requires IT team's permission

### Print some data to output file ###
echo `date`
echo -e "\nSLURM_JOBID:\t\t" $SLURM_JOBID
echo -e "SLURM_JOB_NODELIST:\t" $SLURM_JOB_NODELIST "\n\n"

### Start your src_code below ####
module load anaconda    ### load anaconda module (must be present when working with conda environments)
source activate time_series_nev   ### activate a conda environment, replace my_env with your conda environment
python train_cdsvae.py